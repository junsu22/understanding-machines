# 생성형 AI와 LLM 정리 노트 🧠✨

주말에 혼자 궁금해서 생성형 AI와 LLM에 대해 정리해보았다.  
개념을 따라가다 보니, AI가 어떻게 문장을 이해하고 만들어내는지 흐름이 조금씩 보이기 시작했다.

---

## 1️⃣ 생성형 AI (Generative AI)

**생성형 AI**는  
👉 텍스트, 이미지, 음악 등 **새로운 콘텐츠를 만들어내는 인공지능**이다.

### 생성형 AI의 유형
- **대규모 언어 모델(LLM)** : 텍스트 생성
- **컴퓨터 비전(CV)** : 이미지 생성·분석
- **멀티모달 AI** : 텍스트, 이미지, 음악 등을 함께 처리

---

## 2️⃣ LLM (Large Language Model)

**LLM**은  
👉 **방대한 텍스트 데이터를 학습한 거대 언어 모델**이다.

### 할 수 있는 일
- 질문에 답하기
- 문서 요약
- 자연스러운 문장 생성
- 번역 등 다양한 언어 작업

LLM은 **확률을 기반으로 다음에 올 단어를 예측**하며 문장을 만들어낸다.

---

## 3️⃣ 자연어 처리(NLP)와의 관계

**자연어 처리(NLP)**란  
👉 한국어, 영어, 일본어 등 **사람이 사용하는 언어를 컴퓨터가 이해하고 처리하는 기술**

### NLP 활용 예
- 기계 번역
- 질의 응답
- 문서 요약

LLM은 NLP 기술이 발전하면서 등장한 **언어 모델의 진화된 형태**이다.

---

## 4️⃣ 언어 모델의 발전 과정

### ① 통계적 언어 모델
- 단어와 문장의 **확률**을 기반으로 예측
- 의미 이해에는 한계가 있음

### ② 신경망 기반 언어 모델
- 단어를 벡터로 표현해 의미를 학습
- GPU와 딥러닝 기술 발전(2010년대)으로 본격 성장

#### ▪ Word2Vec
- 단어를 n차원 실수 벡터로 표현
- 문맥에 따른 의미 구분은 어려움  
  (예: ‘사과’가 과일인지 회사인지 구분 불가)

#### ▪ RNN
- 단어를 순차적으로 처리
- 문맥 이해 능력 향상
- ❌ 장기 의존성 문제  
  → 문장이 길어질수록 앞부분 정보가 흐려짐

---

## 5️⃣ 트랜스포머(Transformer)

- **2017년 구글 연구진 발표**
- 문장 전체를 한 번에 처리
- **Attention 메커니즘**을 통해 문맥을 전체적으로 이해

이 구조를 기반으로 **LLM이 본격적으로 등장**했다.

### ChatGPT
- Transformer 구조를 변형한 모델
- 이전 단어를 바탕으로 다음 단어를 예측하며 문장을 생성

---

## 6️⃣ 트랜스포머 구조

### 전체 흐름
데이터 입력 → 인코더(분석) → 디코더(문장 생성)


### 주요 구성 요소
- **Attention** : 단어 간 중요도 계산
- **Feed Forward Network** : 의미를 정교하게 표현
- **Positional Encoding** : 단어의 위치 정보 제공

---

## 7️⃣ 어텐션(Attention) 메커니즘

어텐션은  
👉 문장에서 **어떤 단어가 중요한지 스스로 판단하는 방식**이다.

### 핵심 개념
- **Query** : 무엇이 중요한지 묻는 질문
- **Key** : 비교 대상 단어
- **Value** : 해당 단어가 가진 의미 정보

### 예시
> *“The cat sat on the mat.”*

- Query: cat  
- Key: sat, mat  
- Value: 각 단어의 의미 정보  

### 처리 과정
1. 중요한 단어를 묻는다
2. 단어 간 관계를 비교한다
3. 의미 정보를 종합해 문장을 이해한다

---

## 8️⃣ LLM의 한계

- **신뢰성 문제**  
  → 답변은 하지만 근거 설명이 부족할 수 있음
- **환각(Hallucination)**  
  → 존재하지 않는 정보 생성
- **최신성 부족**  
  → 학습 이후 정보 업데이트 불가
- **데이터 보안 및 편향 문제**  
  → 개인정보, 사회적 편향 발생 가능
- **외부 데이터 활용의 어려움**

---

## 9️⃣ 한계 보완 기술

LLM의 단점을 보완하기 위한 기술들이 등장했다.

- **RAG (Retrieval-Augmented Generation)**  
  → 외부 데이터를 검색해 답변에 활용
- **파인튜닝(Fine-tuning)**  
  → 특정 목적에 맞게 추가 학습
- **에이전트(Agent) 기술**  
  → 도구 활용과 추론 능력 강화

---

## 마무리 ✨

생성형 AI와 LLM은  
단순히 “답을 잘하는 AI”가 아니라,  
**언어를 확률과 관계로 이해하려는 기술의 집합**이라는 점이 인상 깊었다.

아직 완벽히 이해했다고 말하긴 어렵지만,  
흐름을 잡는 데는 도움이 된 정리였다.
